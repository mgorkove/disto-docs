---
title: Deploy LLM on AWS Sagemaker
description: ""
---

Disto uses the state-of-the-art Llama model from Meta as its underlying LLM. Follow the instructions below to deploy this LLM on AWS Sagemaker.

1. Go to "Amazon Sagemaker" in the AWS console. Click on "Studio" in the left sidebar.

<img height="70" src="/images/sagemaker-studio.png" />

2. Choose your user profile and click "Open Studio".

<img height="70" src="/images/open-sagemaker-studio.png" />

3. Click on "Jumpstart".

<img height="70" src="/images/jumpstart.png" />

4. Search for your preferred Llama model in the search bar and click on it. We recommend "Llama-2-70b-chat", as it is most accurate, but you can choose a smaller model if you wish.

<img height="70" src="/images/llama-model.png" />

5. Click on "deploy". Wait for the model to deploy.

<img height="70" src="/images/sagemaker-deploy.png" />

6. Copy your Endpoint name. This will be the value for **sagemaker-endpoint-name** in the deploy script.

<img height="70" src="/images/sagemaker-endpoint-name.png" />

7. If you wish to delete the endpoint, click on "delete".

<img height="70" src="/images/sagemaker-delete-endpoint.png" />
